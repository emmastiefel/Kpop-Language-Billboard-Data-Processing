{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "lyrics-env",
   "display_name": "lyrics-env",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "h100_subcharts = pd.read_csv('hot100_radio_streaming_sales_Kpop.csv')\n",
    "wdss = pd.read_csv('wdss.csv')\n",
    "\n",
    "## create standardized search_title column for wdss to match other set\n",
    "wdss['search_title'] = wdss['song_title'].str.replace(r\"(\\(.*\\))\", \"\")\n",
    "wdss['search_title'] = wdss['search_title'].str.strip()\n",
    "\n",
    "##match wdss processing to h100/subcharts processing\n",
    "#clean spacing: add space before linebreaks (so theyre counted separately)\n",
    "wdss[\"translated_lyrics\"] = wdss[\"translated_lyrics\"].str.replace(r\"(\\n+)\", \" \\n\")\n",
    "wdss[\"translated_lyrics\"] = wdss[\"translated_lyrics\"].str.replace(r\"(\\s+)\", \" \") #restandardize whitespace\n",
    "wdss[\"translated_lyrics\"] = wdss[\"translated_lyrics\"].str.replace(r\"(\\s[, | \\' | \\? | \\! | \\. | \\-]+)\", \" \")  #delete hanging punctuation\n",
    "\n",
    "wdss[\"original_lyrics\"] = wdss[\"original_lyrics\"].str.replace(r\"(\\n+)\", \" \\n\")\n",
    "wdss[\"original_lyrics\"] = wdss[\"original_lyrics\"].str.replace(r\"(\\s+)\", \" \") #restandardize whitespace\n",
    "wdss[\"original_lyrics\"] = wdss[\"original_lyrics\"].str.replace(r\"(\\s[, | \\' | \\? | \\! | \\. | \\-]+)\", \" \")  #delete hanging punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nFalse\nFalse\nTrue\n"
     ]
    }
   ],
   "source": [
    "## redo word classifying and sorting to focus on tokenized words instead of the whole string\n",
    "\n",
    "# define function to classify words as roman/presumably english if it contains a roman letter\n",
    "def is_roman(word):\n",
    "    if re.search(\"[A-Z | a-z ]\", word):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#test to make sure it classifies words as desired\n",
    "#we will count numeric characters as part of \"original\" because often they are pronounced in korean\n",
    "# ie, '2!3!' is sung as 'dul! set!'\n",
    "print(is_roman('h1'))\n",
    "print(is_roman('h'))\n",
    "print(is_roman('1'))\n",
    "print(is_roman('거짓이'))\n",
    "print(is_roman('h거짓이'))\n",
    "\n",
    "#there are a few cases where roman words and non-roman words are smushed together, but they are rare and we'll still count them as roman/english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redo counting english words - wdss\n",
    "for i, r in wdss.iterrows():\n",
    "\n",
    "    #tokenize words\n",
    "    this_original = r['original_lyrics'].split(' ')\n",
    "    this_english = [] #list to store words classified as roman/english (in some cases though these could be spanish or french, so)\n",
    "    #determine if word contains roman characters or not\n",
    "    for word in this_original:\n",
    "        if is_roman(word):\n",
    "            this_english.append(word)\n",
    "\n",
    "    #combine words into 1 string\n",
    "    this_english = ' '.join(this_english)\n",
    "    wdss.at[i, 'english_lyrics'] = this_english\n",
    "\n",
    "#redo counting english words - h100_subcharts\n",
    "for i, r in h100_subcharts.iterrows():\n",
    "\n",
    "    #tokenize words\n",
    "    this_original = r['original_lyrics'].split(' ')\n",
    "    this_english = [] #list to store words classified as roman/english (in some cases though these could be spanish or french, so)\n",
    "    #determine if word contains roman characters or not\n",
    "    for word in this_original:\n",
    "        if is_roman(word):\n",
    "            this_english.append(word)\n",
    "\n",
    "    #combine words into 1 string\n",
    "    this_english = ' '.join(this_english)\n",
    "    h100_subcharts.at[i, 'english_lyrics'] = this_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "##count number of english lyrics and total lyrics\n",
    "wdss['english_count'] = [len(str(lyr).split(\" \")) for lyr in wdss['english_lyrics']]\n",
    "wdss['total_count'] = [len(str(lyr).split(\" \")) for lyr in wdss['original_lyrics']]\n",
    "\n",
    "### create columns for english percentage\n",
    "h100_subcharts['english_percentage'] = h100_subcharts['english_count'] / h100_subcharts['total_count']\n",
    "wdss['english_percentage'] = wdss['english_count'] / wdss['total_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Song  Life Goes On\n29    0.34981\nName: english_percentage, dtype: float64 perc. english in h100/subcharts\n1230    0.346008\nName: english_percentage, dtype: float64 perc. english in wdss\nENGLISH COUNTS:\n29    92\nName: english_count, dtype: int64 h100/subcharts\n1230    91\nName: english_count, dtype: int64 wdss\nTOTAL COUNTS:\n29    263\nName: total_count, dtype: int64 h100/subcharts\n1230    263\nName: total_count, dtype: int64 wdss\n"
     ]
    }
   ],
   "source": [
    "##test on one song to see if they match\n",
    "test_title = 'Life Goes On'\n",
    "h100_value = h100_subcharts.loc[h100_subcharts['search_title'] == test_title]['english_percentage']\n",
    "wdss_value = wdss.loc[wdss['search_title'] == test_title]['english_percentage']\n",
    "print('Song ', test_title)\n",
    "print(h100_value, 'perc. english in h100/subcharts')\n",
    "print(wdss_value, 'perc. english in wdss')\n",
    "print('ENGLISH COUNTS:')\n",
    "print(h100_subcharts.loc[h100_subcharts['search_title'] == test_title]['english_count'], 'h100/subcharts')\n",
    "print(wdss.loc[wdss['search_title'] == test_title]['english_count'], 'wdss')\n",
    "print('TOTAL COUNTS:')\n",
    "print(h100_subcharts.loc[h100_subcharts['search_title'] == test_title]['total_count'], 'h100/subcharts')\n",
    "print(wdss.loc[wdss['search_title'] == test_title]['total_count'], 'wdss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "yeah oh Like an echo in the forest Yeah, life goes on Like an arrow in the blue sky On my pillow, on my table Yeah, life goes on Like this again (Ayy) (No) Mm-mm-mm-mm (Ooh, ooh, ooh, oh-woah) oh (Oh, oh, oh) Like an echo in the forest Yeah, life goes on (Oh, woah) Like an arrow in the blue sky On my pillow, on my table Yeah, life goes on Like this again I remember I, yeah-yeah-yeah-yeah I remember Ah-ah, ah-ah I remember I, yeah-yeah-yeah-yeah I remember Ah-ah, ah-ah\n"
     ]
    }
   ],
   "source": [
    "### verify lyrics for both datsets look correct for test song\n",
    "for i, r in h100_subcharts.iterrows():\n",
    "    if r['search_title'] == test_title:\n",
    "        print(r['english_lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "yeah oh Like an echo in the forest Yeah, life goes on Like an arrow in the blue sky On my pillow, on my table Yeah, life goes on Like this again (Ayy) (No) Mm-mm-mm-mm (Ooh, ooh, ooh, oh-woah) oh (Oh, oh, oh) Like an echo in the forest Yeah, life goes on (Oh, woah) Like an arrow in the blue sky On my pillow, on my table Yeah, life goes on Like this again I remember I, yeah-yeah-yeah-yeah I remember Ah-ah, ah-ah I remember I, yeah-yeah-yeah-yeah I remember Ah-ah, ah-ah\n"
     ]
    }
   ],
   "source": [
    "for i, r in wdss.iterrows():\n",
    "    if r['search_title'] == test_title:\n",
    "        print(r['english_lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### identify all songs in both datasets and make sure they have matching lyrics info\n",
    "common_songs = h100_subcharts.merge(wdss, how='inner', on=['search_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   search_title               artist_x            artist_y  total_count_y  \\\n",
       "6     Fake Love                    BTS                 BTS            409   \n",
       "9          Idol  BTS feat. Nicki Minaj                 BTS            356   \n",
       "14   Black Swan                    BTS                 BTS            379   \n",
       "16           On                    BTS                 BTS            410   \n",
       "21     Dynamite                    BTS                VIXX            286   \n",
       "27         Stay                    BTS             Taeyeon            105   \n",
       "28         Stay                    BTS                 BTS            235   \n",
       "37         Home                    BTS           Seventeen            272   \n",
       "38         Home                    BTS                 BTS            413   \n",
       "40     Dionysus                    BTS                 BTS            514   \n",
       "46    All Night     BTS and Juice Wrld               ASTRO            328   \n",
       "47    All Night     BTS and Juice Wrld  BTS and Juice Wrld            610   \n",
       "49    Heartbeat                    BTS                 BTS            326   \n",
       "\n",
       "    total_count_x  \n",
       "6             408  \n",
       "9             430  \n",
       "14            378  \n",
       "16            409  \n",
       "21            469  \n",
       "27            234  \n",
       "28            234  \n",
       "37            412  \n",
       "38            412  \n",
       "40            513  \n",
       "46            609  \n",
       "47            609  \n",
       "49            325  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>search_title</th>\n      <th>artist_x</th>\n      <th>artist_y</th>\n      <th>total_count_y</th>\n      <th>total_count_x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>Fake Love</td>\n      <td>BTS</td>\n      <td>BTS</td>\n      <td>409</td>\n      <td>408</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Idol</td>\n      <td>BTS feat. Nicki Minaj</td>\n      <td>BTS</td>\n      <td>356</td>\n      <td>430</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Black Swan</td>\n      <td>BTS</td>\n      <td>BTS</td>\n      <td>379</td>\n      <td>378</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>On</td>\n      <td>BTS</td>\n      <td>BTS</td>\n      <td>410</td>\n      <td>409</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Dynamite</td>\n      <td>BTS</td>\n      <td>VIXX</td>\n      <td>286</td>\n      <td>469</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Stay</td>\n      <td>BTS</td>\n      <td>Taeyeon</td>\n      <td>105</td>\n      <td>234</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Stay</td>\n      <td>BTS</td>\n      <td>BTS</td>\n      <td>235</td>\n      <td>234</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Home</td>\n      <td>BTS</td>\n      <td>Seventeen</td>\n      <td>272</td>\n      <td>412</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Home</td>\n      <td>BTS</td>\n      <td>BTS</td>\n      <td>413</td>\n      <td>412</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Dionysus</td>\n      <td>BTS</td>\n      <td>BTS</td>\n      <td>514</td>\n      <td>513</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>All Night</td>\n      <td>BTS and Juice Wrld</td>\n      <td>ASTRO</td>\n      <td>328</td>\n      <td>609</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>All Night</td>\n      <td>BTS and Juice Wrld</td>\n      <td>BTS and Juice Wrld</td>\n      <td>610</td>\n      <td>609</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Heartbeat</td>\n      <td>BTS</td>\n      <td>BTS</td>\n      <td>326</td>\n      <td>325</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "target_col = 'total_count'\n",
    "common_songs.loc[common_songs[target_col+'_y'] != common_songs[target_col+'_x']][['search_title', 'artist_x', 'artist_y', target_col+'_y', target_col+'_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Let's go, yeah, yeah, yeah 타닥 또 타오르는 저 불씨 기름에 닿기 전에 먼저 집어삼키네 필시 휩쓸려가겠지 예 예 음 오늘의 선수 입장하시네 건수를, yeah 물기 시작하면 둥둥둥 동네북이 돼 둥둥둥 툭툭 건드네 괜시리 툭툭, yeah 반응이 없음 걍 담궈버리지 푹푹, yeah 진실도 거짓이 돼 거짓도 진실이 돼 이곳에선 모두가 도덕적 사고와 판단이 완벽한 사람이 돼 웃기시네 분노? 물론 필요하지 타오를 땐 이유가 있어 어쩌면 우리의 역사지 그게 세상을 바꾸기도 하지 But 이건 분노 아닌 분뇨 뭐가 분노인지 you know? 분노인 척하며 죽여 진짜 분노 질려버린 수도 없이 많은 people 넌 나만 죽이는 게 아니야 (아니야) 똥 밟는 게 익숙해 우리야 (우리야) 무감각해진 저 사람들 봐 (봐) 분뇨, 무관심 너넨 팀이야, yeah (19115977) 나는 악의에 가득 찬 분노에 분노해 나는 악의에 가득 찬 분노에 분노해 나는 욱해 욱해 나는 욱해 욱해 나는 꺼져야만 했던 분노에 분노해 나는 꺼져야만 했던 그 분노에 분노해 (Yeah, yeah) 그래 욱 욱 욱해라 욱 재가 될 때까지 그래 욱해라 욱 그래 욱 욱 욱해라 욱 부러질 때까지 그래 욱해라 욱 나는 욱해 욱해 나는 욱해 욱해 나는 악의에 가득 찬 분노에 분노해 나는 꺼져야만 했던 그 분노에 분노해 이 세상 분노가 지배함 분노가 없음 다 못 사나 봐 분노하고 또 분노하고 분노하고 그리 미쳐가고 욱 욱 욱 욱 분노하는 이유도 다 수만 가지 선의와 악의도 다 매한가지 분노할 수 있다만 남의 삶에 피해가 있는 건 I don’t like 그건 stop, ayy 누구의 행동에 누구는 아파해 누구의 언행에 누구는 암담해 누구의 찰나에 누구 순간이 돼 누구의 분노에 누구 목숨이 돼 썩을 퉤 나는 욱해 욱해 나는 욱해 욱해 나는 악의에 가득 찬 분노에 분노해 나는 꺼져야만 했던 그 분노에 분노해 아 대체 욕 좀 먹는 게 왜 잘 벌잖아 또 징징대 왜 그 정돈 감수해야지 에헴 에헴 에헴 에헴 에헴 니네 에헴 에헴 에헴 에헴 나 시켰어봐 다 참아 니네 에헴 니네 에헴 에헴 에헴 에헴 나 시켰어봐 그냥 에헴 비헴 에헴 그래 욱 (욱) 욱 (욱) 욱해라 욱 (욱) 재가 될 때까지 그래 욱해라 욱 (욱) 그래 욱 (욱) 욱 (욱) 욱해라 욱 부러질 때까지 그래 욱해라 욱 나는 욱해 욱해 나는 욱해 욱해 나는 악의에 가득 찬 분노에 분노해 나는 꺼져야만 했던 그 분노에 분노해 (Hey, hey) Let's go\n"
     ]
    }
   ],
   "source": [
    "### verify lyrics for both datsets look correct for test song\n",
    "for i, r in h100_subcharts.iterrows():\n",
    "    if r['search_title'] == 'Ugh!':\n",
    "        print(r['original_lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Let's go, yeah, yeah, yeah 타닥 또 타오르는 저 불씨 기름에 닿기 전에 먼저 집어삼키네 필시 휩쓸려가겠지 예 예 음 오늘의 선수 입장하시네 건수를, yeah 물기 시작하면 둥둥둥 동네북이 돼 둥둥둥 툭툭 건드네 괜시리 툭툭, yeah 반응이 없음 걍 담궈버리지 푹푹, yeah 진실도 거짓이 돼 거짓도 진실이 돼 이곳에선 모두가 도덕적 사고와 판단이 완벽한 사람이 돼 웃기시네 분노? 물론 필요하지 타오를 땐 이유가 있어 어쩌면 우리의 역사지 그게 세상을 바꾸기도 하지 But 이건 분노 아닌 분뇨 뭐가 분노인지 you know? 분노인 척하며 죽여 진짜 분노 질려버린 수도 없이 많은 people 넌 나만 죽이는 게 아니야 (아니야) 똥 밟는 게 익숙해 우리야 (우리야) 무감각해진 저 사람들 봐 (봐) 분뇨, 무관심 너넨 팀이야, yeah (19115977) 나는 악의에 가득 찬 분노에 분노해 나는 악의에 가득 찬 분노에 분노해 나는 욱해 욱해 나는 욱해 욱해 나는 꺼져야만 했던 분노에 분노해 나는 꺼져야만 했던 그 분노에 분노해 (Yeah, yeah) 그래 욱 욱 욱해라 욱 재가 될 때까지 그래 욱해라 욱 그래 욱 욱 욱해라 욱 부러질 때까지 그래 욱해라 욱 나는 욱해 욱해 나는 욱해 욱해 나는 악의에 가득 찬 분노에 분노해 나는 꺼져야만 했던 그 분노에 분노해 이 세상 분노가 지배함 분노가 없음 다 못 사나 봐 분노하고 또 분노하고 분노하고 그리 미쳐가고 욱 욱 욱 욱 분노하는 이유도 다 수만 가지 선의와 악의도 다 매한가지 분노할 수 있다만 남의 삶에 피해가 있는 건 I don’t like 그건 stop, ayy 누구의 행동에 누구는 아파해 누구의 언행에 누구는 암담해 누구의 찰나에 누구 순간이 돼 누구의 분노에 누구 목숨이 돼 썩을 퉤 나는 욱해 욱해 나는 욱해 욱해 나는 악의에 가득 찬 분노에 분노해 나는 꺼져야만 했던 그 분노에 분노해 아 대체 욕 좀 먹는 게 왜 잘 벌잖아 또 징징대 왜 그 정돈 감수해야지 에헴 에헴 에헴 에헴 에헴 니네 에헴 에헴 에헴 에헴 나 시켰어봐 다 참아 니네 에헴 니네 에헴 에헴 에헴 에헴 나 시켰어봐 그냥 에헴 비헴 에헴 그래 욱 (욱) 욱 (욱) 욱해라 욱 (욱) 재가 될 때까지 그래 욱해라 욱 (욱) 그래 욱 (욱) 욱 (욱) 욱해라 욱 부러질 때까지 그래 욱해라 욱 나는 욱해 욱해 나는 욱해 욱해 나는 악의에 가득 찬 분노에 분노해 나는 꺼져야만 했던 그 분노에 분노해 (Hey, hey) Let's go\n"
     ]
    }
   ],
   "source": [
    "### verify lyrics for both datsets look correct for test song\n",
    "for i, r in wdss.iterrows():\n",
    "    if r['search_title'] == 'Ugh!':\n",
    "        print(r['original_lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong lyrics were identified for gangnam style in wdss....\n",
    "# h100 is idoll ft. nicki minaj, wdss is idol original version, but they should both be nicki minaj version\n",
    "# h100 has correct all night lyrics, wdss incorrectly matched it to glory by rm ':|\n",
    "# ugh! is onlly off by a few words for each dataset so I will let it go\n",
    "\n",
    "##so basically h100 had correct versions, will overwrite wdss to that\n",
    "\n",
    "# would be good to do random checks for other wdss songs if time since mismatched songs obviously happened\n",
    "# (redo it now that ive figured out more accurate way of using genius search??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fake Love\nIdol\nBlack Swan\nOn\nDynamite\nStay\nStay\nHome\nHome\nDionysus\nAll Night\nAll Night\nHeartbeat\n"
     ]
    }
   ],
   "source": [
    "## overwrite wdss mistakes with h100 info\n",
    "to_correct = list(common_songs.loc[common_songs[target_col+'_y'] != common_songs[target_col+'_x']]['search_title'])\n",
    "\n",
    "for song in to_correct:\n",
    "    print(song)\n",
    "    #locate song in each dataset\n",
    "    h100_index = h100_subcharts.loc[h100_subcharts['search_title'] == song].index[0]\n",
    "    wdss_index = wdss.loc[wdss['search_title'] == song].index[0]\n",
    "\n",
    "    ##overwrite wdss info with h100 info\n",
    "    wdss.at[wdss_index, 'original_lyrics'] = h100_subcharts.at[h100_index, 'original_lyrics']\n",
    "    wdss.at[wdss_index, 'english_lyrics'] = h100_subcharts.at[h100_index, 'english_lyrics']\n",
    "    wdss.at[wdss_index, 'translated_lyrics'] = h100_subcharts.at[h100_index, 'translated_lyrics']\n",
    "    wdss.at[wdss_index, 'english_count'] = h100_subcharts.at[h100_index, 'english_count']\n",
    "    wdss.at[wdss_index, 'total_count'] = h100_subcharts.at[h100_index, 'total_count']\n",
    "    wdss.at[wdss_index, 'english_percentage'] = h100_subcharts.at[h100_index, 'english_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   peak_position_radio chart_date_radio\n",
       "2                 12.0       2012-10-26"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>peak_position_radio</th>\n      <th>chart_date_radio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>12.0</td>\n      <td>2012-10-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "### correct wikipedia mistake, add gangnam style to radio chart\n",
    "\n",
    "gangnam_i = h100_subcharts.loc[h100_subcharts['search_title'] == 'Gangnam Style'].index[0]\n",
    "h100_subcharts.at[gangnam_i, 'peak_position_radio'] = 12\n",
    "h100_subcharts.at[gangnam_i, 'chart_date_radio'] = '2012-10-26'\n",
    "h100_subcharts.loc[h100_subcharts['search_title'] == 'Gangnam Style'][['peak_position_radio', 'chart_date_radio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overwrite each csv with the updated datasets\n",
    "h100_subcharts.to_csv('hot100_radio_streaming_sales_Kpop.csv')\n",
    "wdss.to_csv('wdss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}